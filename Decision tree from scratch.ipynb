{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "499db131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19a464ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9122807017543859\n"
     ]
    }
   ],
   "source": [
    "class Node:\n",
    "    def __init__(self,feature_index = None, threshold = None, left = None, right = None,*,value = None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right =right\n",
    "        self.value = value\n",
    "    \n",
    "    #to check whether it is leaf node or not\n",
    "    def is_leaf_node(self):\n",
    "        return self.value is not None\n",
    "    \n",
    "    \n",
    "# create a decision tree\n",
    "class Decision_tree:\n",
    "    def __init__(self,min_samples_split =10, max_depth = 100, n_features= None):\n",
    "        \n",
    "        self.min_samples_split = min_samples_split          #specifies the minimum number of samples required \n",
    "                                                                   #to split an internal node into two branches.\n",
    "        self.max_depth = max_depth                          # to intialize the max depth to how long the tree can grow\n",
    "        self.n_features = n_features                        # to declare the no of features needed\n",
    "        self.root = None                                    # to acces the root of the tree\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \n",
    "        #this line ensures that the n_features shouldn't exceed the X.shape \n",
    "        self.n_features= X.shape[1] if not self.n_features else min(X.shape[1],self.n_features)\n",
    "        \n",
    "        #helper function\n",
    "        self.root = self._grow_tree(X,y)\n",
    "        \n",
    "        \n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def _grow_tree(self,X,y,depth = 0):\n",
    "        n_samples, n_feats = X.shape\n",
    "        n_labels = len(np.unique(y))        #gives the n labels\n",
    "        \n",
    "        #check the stopping criteria (provide a criteria)\n",
    "        \n",
    "        \n",
    "        if (depth>=self.max_depth or n_labels ==1 or n_samples< self.min_samples_split):  #if condtion meets leaf value will be return\n",
    "            leaf_value = self._most_common_label(y)  \n",
    "            return Node(value = leaf_value)                                                #this will return the leaf value\n",
    "        \n",
    "        \n",
    "        feat_indexs = np.random.choice(n_feats,self.n_features, replace= False) #to get the unique features while updating the group\n",
    "        \n",
    "        #find the best split\n",
    "        best_feature,best_threshold = self._best_split(X,y,feat_indexs)\n",
    "        \n",
    "        #create child nodes by(accesing the _grow_tree function)\n",
    "        left_idxs,right_idxs = self._split(X[:,best_feature], best_threshold)\n",
    "        left =  self._grow_tree(X[left_idxs,:],y[left_idxs], depth+1)\n",
    "        right = self._grow_tree(X[right_idxs,:],y[right_idxs],depth+1)\n",
    "        return Node(best_feature,best_threshold,left,right)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _best_split(self,X,y,feat_indexs):\n",
    "        best_gain = -1                               # Initialize best gain to a very low value\n",
    "        split_index = None                           # To store the index of the best feature for the split\n",
    "        split_threshold = None                       # To store the best threshold for the split\n",
    "        \n",
    "        \n",
    "        for feat_index in feat_indexs:                # Iterate over all feature indices\n",
    "            X_column = X[:,feat_index]                # Extract the values of the current feature (column)\n",
    "            thresholds= np.unique(X_column)           # Get unique values (thresholds) in the current feature\n",
    "            \n",
    "            for thr in thresholds:                              # Iterate over all unique thresholds (possible split points)\n",
    "                #to calculate the inforamtion gain\n",
    "                gain  = self._information_gain(y,X_column,thr)        # Calculate the information gain for the current feature and threshold\n",
    "                                                                  # information gain using helper funtion\n",
    "                \n",
    "             # if the gain is better than the best found till now, upadte the best_split parameters\n",
    "        \n",
    "                if gain >best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_index = feat_index\n",
    "                    split_threshold = thr\n",
    "                    \n",
    "        return split_index,split_threshold\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        ## INFORMATION GAIN USING ENTROPY\n",
    "        \n",
    "        \n",
    "#     def _information_gain(self,y,X_column,threshold):\n",
    "        \n",
    "        \n",
    "#         # parent entropy\n",
    "#         parent_entropy = self._entropy(y)\n",
    "                                    \n",
    "#         #create children\n",
    "#         left_idxs,right_idxs= self._split(X_column,threshold)\n",
    "        \n",
    "#         if len(left_idxs)==0 or len(right_idxs) ==0:\n",
    "#             return 0\n",
    "        \n",
    "#         #calculate the weighted average of the entropy of the children\n",
    "#         n = len(y)\n",
    "#         n_left,n_right = len(left_idxs), len(right_idxs)\n",
    "#         e_left,e_right = self._entropy(y[left_idxs]),self._entropy(y[right_idxs])\n",
    "        \n",
    "#         child_entropy = (n_left/n) * e_left / (n_right/n) * e_right   \n",
    "        \n",
    "#         #Calculate the information gain\n",
    "        \n",
    "#         information_gain = parent_entropy - child_entropy\n",
    "#         return information_gain\n",
    "        \n",
    "     \n",
    "        \n",
    "        ## INFORMATION GAIN USING GINI INDEX\n",
    "        \n",
    "    def _information_gain(self, y, X_column, threshold):\n",
    "        # Use Gini impurity \n",
    "        parent_gini = 1 - np.sum((np.bincount(y) / len(y)) ** 2)\n",
    "        left_idxs, right_idxs = self._split(X_column, threshold)\n",
    "        if len(left_idxs) == 0 or len(right_idxs) == 0:\n",
    "            return 0\n",
    "        left_gini = 1 - np.sum((np.bincount(y[left_idxs]) / len(left_idxs)) ** 2)\n",
    "        right_gini = 1 - np.sum((np.bincount(y[right_idxs]) / len(right_idxs)) ** 2)\n",
    "        child_gini = (len(left_idxs) / len(y)) * left_gini + (len(right_idxs) / len(y)) * right_gini\n",
    "        return parent_gini - child_gini\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def _split(self,X_column,split_threshold):\n",
    "        \n",
    "        # Get indices of the data points that belong to the left and right node (<= threshold,>threshold)\n",
    "        \n",
    "        left_idxs = np.argwhere(X_column <= split_threshold).flatten()   #argwhere is used to convert the output from 2d array to 1d array\n",
    "        right_idxs =np.argwhere(X_column > split_threshold).flatten()\n",
    "        \n",
    "        return left_idxs,right_idxs\n",
    "        \n",
    "        \n",
    "\n",
    "    # Entropy formula =  -summization(p(x))*log2(p(x))\n",
    "    \n",
    "    def _entropy(self,y):            \n",
    "        hist  = np.bincount(y)                   #it will create a histogram of number(telling the no. of times a digit occurs)\n",
    "        ps  = hist/len(y)                        # formula for p(x)  = number of times class appeared / number of total nodes\n",
    "        \n",
    "        return -np.sum([p* np.log(p) for p in ps if p>0])   #formula for entropy with a condition\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _most_common_label(self,y):                 # helper function to get the most common leaf value\n",
    "        common = Counter(y)\n",
    "        value = common.most_common(1)[0][0]\n",
    "        return value\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def _traverse_tree(self, x, node):\n",
    "        if node.is_leaf_node():\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature_index] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = datasets.load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "clf = Decision_tree(min_samples_split=20,max_depth=25)\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "def accuracy(y_test, y_pred):\n",
    "    return np.sum(y_test == y_pred) / len(y_test)\n",
    "\n",
    "acc = accuracy(y_test, predictions)\n",
    "print(acc)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
